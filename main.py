import os
import requests
import json
import subprocess
from configparser import ConfigParser


HOME = "http://localhost:11434"


def get_config():
    config = ConfigParser()
    if not os.path.exists("config.ini"):
        # init config
        config["DEFAULT"] = {
            "model": "",
            "stream": "True",
        }
        with open("config.ini", "w") as f:
            config.write(f)

    config.read("config.ini")
    return {
        "model": config["DEFAULT"]["model"],
        "stream": config["DEFAULT"]["stream"],
    }


def request_api(model, text, stream=True, keep_alive="5m"):
    url = HOME + "/api/generate"

    payload = {
        # æ¨¡å‹åç§°
        "model": model,
        # å¯¹è¯å†…å®¹
        "prompt": text,
        # æ˜¯å¦æµå¼ç”Ÿæˆ
        "stream": stream,
        # å¯¹è¯é¢„è®¾
        # "template": "",
        # æ¨¡å‹å­˜æ´»æ—¶é—´
        "keep_alive": keep_alive,
    }
    response = requests.post(url, json=payload, stream=stream, timeout=99999)

    os.system("cls")
    print("\nğŸ˜½ >> ", end="")

    if response.status_code != 200:
        print("Error:", response.status_code)
        print(response.json())
        return

    if stream:
        for chunk in response.iter_content(chunk_size=1024):
            print(json.loads(chunk)["response"], end="")
    else:
        print(response.text)
        print(response.json()["response"])


def get_model_list():
    results = []
    url = HOME + "/api/tags"
    response = requests.get(url)
    response = response.json()
    models = response["models"]
    for model in models:
        result = {
            "name": model["name"],
            "size": f"{round(model['size'] / 1024**3, 2):.2f} G",
            "family": model["details"]["family"],
            "par_size": model["details"]["parameter_size"],
        }
        results.append(result)
    return sorted(results, key=lambda x: x["family"])


def main_loop(model, stream):
    first_input = 1
    text = ""
    while True:
        if first_input:
            text = input("\nğŸ¤” >> ")
            first_input = 0

        os.system("cls")
        # print("\nCAT >> Generating...", end="")
        print("\nğŸ˜½ >> Generating...", end="")
        request_api(model, text, stream=stream)
        text = input("\nğŸ¤¯ >> ")


if __name__ == "__main__":
    # å¯åŠ¨ Ollama æœåŠ¡å™¨
    subprocess.Popen(
        "ollama serve", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
    )

    # è·å–é…ç½®æ–‡ä»¶
    config = get_config()
    model = ""
    stream = bool(config["stream"])

    os.system("title QuickOllama V2")
    os.system("cls")

    # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æœ‰æ¨¡å‹åç§°ï¼Œåˆ™ç›´æ¥å¼€å§‹å¯¹è¯
    if config["model"]:
        model = config["model"]
        os.system(f"title {model.split(':')[0]} - QuickOllama V2")
        main_loop(model, stream)

    # å¦åˆ™ï¼Œåˆ—å‡ºæ¨¡å‹åˆ—è¡¨ä¾›ç”¨æˆ·é€‰æ‹©
    print("æ¨¡å‹åˆ—è¡¨:\n")
    print("åŠ è½½ä¸­...\n")
    models = get_model_list()

    os.system("cls")
    print("æ¨¡å‹åˆ—è¡¨:\n")
    for index in range(len(models)):
        model_ = models[index]
        print(
            f"{index + 1}. {model_['name'].ljust(20)}",
            f"ç±»åˆ«: {model_['family'].ljust(10)}",
            f"å¤§å°: {model_['size'].ljust(10)}",
            f"å‚æ•°å¤§å°: {model_['par_size']}",
        )
    index = input("\nè¯·è¾“å…¥åºå·: ")

    if index not in [str(i) for i in range(1, len(models) + 1)]:
        print("è¾“å…¥æœ‰è¯¯")
    else:
        model = models[int(index) - 1]["name"]
        os.system(f"title {model.split(':')[0]} - QuickOllama V2")
        os.system("cls")
        print(f"\né€‰æ‹©æ¨¡å‹: {model}")

    main_loop(model, stream)
